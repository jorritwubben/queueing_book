\section
{$M(n)/M(n)/1$ Queue}
%{$\mathbf{M(n)/M(n)/1}$ Queue}
\label{sec:mnmn1}


\opt{solutionfiles}{
\subsection*{Theory and Exercises}
\Opensolutionfile{hint}
\Opensolutionfile{ans}
}

As it turns out, many more single-server queueing situations than the $M/M/1$ queue can be analyzed by making a judicious choice of $\lambda(n)$ and $\mu(n)$ in the level-crossing equations~\cref{eq:25}.
For these queueing systems, we just present the results.
In the exercises we ask you to derive the formulas---the main challenge is not to make computational errors.

It is important to realize that the inter-arrival times and service times need to be memoryless for the analysis below; the rates, however, may depend on the number of jobs in the system. Specifically, we require that for all $s$ and $t$,
\begin{equation*}
 \P{A_{A(t)+1} \leq t+s \given L(t) = n} = 1-e^{-\lambda(n) s},
\end{equation*}
where we use that $A_{A(t)}+g$ is the arrival time of the next job after time $t$.
Similarly, we assume for all $t$ and $s$,
\begin{equation*}
 \P{D_{D(t)+1} \leq t+s \given L(t)=n} = 1-e^{-\mu(n) s}.
\end{equation*}


\begin{exercise}\clabel{ex:l-244}
 Model the $M/M/1/K$ queue in terms of an $M(n)/M(n)/1$ queue and compute $p(K)$, i.e., the fraction of time that the system is full.
\begin{hint}
 Take $\lambda(n) = \lambda \1{n < K}$, $\mu(n) = \mu$, use the equations around~\cref{eq:38}.
\end{hint}
\begin{solution}
Note that 
\begin{equation*}
1 = \sum_{i=0}^K p(i) = p(0)\sum_{i=0}^K \rho^i = p(0) \frac{1-\rho^{K+1}}{1-\rho}. 
\end{equation*}
Thus,
\begin{subequations}\label{eq:8}
 \begin{align}
p(n) &= \frac{\rho^n}G, \quad 0\leq n \leq K,\\
p(K) &= \frac{1-\rho}{1-\rho^{K+1}} \rho^K.
\end{align}
\end{subequations}
\end{solution}
\end{exercise}

\begin{extra}\clabel{ex:40}
 Show that as $K\to\infty$, the performance measures of the $M/M/1/K$ converge to those of the $M/M/1$ queue. 
\begin{hint}
Use that $\sum_{i=0}^n x^i = (1-x^{n+1})/(1-x)$. BTW, is it
 necessary for this expression to be true that $|x|<1$? What should
 you require for $|x|$ when you want to take the limit
 $n\to\infty$?
\end{hint}
\begin{solution}
To take the limit $K\to\infty$---mind, not the limit $n\to\infty$---, write
\begin{equation*}
G= \frac{1-\rho^{K+1}}{1-\rho} = \frac{1}{1-\rho} -\frac{\rho^{K+1}}{1-\rho}.
\end{equation*}
Since $\rho^{K+1}\to 0$ as $K\to \infty$ (recall, $\rho<1$), we get
\begin{equation*}
G \to \frac{1}{1-\rho}, 
\end{equation*}
as $K\to\infty$. Therefore, $p(n)=\rho^n/G \to \rho^n(1-\rho)$, and
the latter are the steady-state probabilities of the $M/M/1$
queue. Finally, if the steady-state probabilities are the same, the
performance measures (which are derived from $p(n)$) must be the same.
\end{solution}
\end{extra}

\begin{exercise}\clabel{ex:7}
 Model the $M/M/c$ queue in terms of an $M(n)/M(n)/1$ queue and compute $\E{L_Q}$. 
\begin{hint}
Take $\lambda(n) = \lambda,$ and $\mu(n) = \min\{n, c\} \mu$. 
\end{hint}
\begin{solution}
First we use the hint to establish a generic relation for $p(n)$. Taking $\rho=\lambda/(c\mu)$, 
 \begin{align*}
 p(n) 
 &= \frac{\lambda(n-1)}{\mu(n)}p(n-1) 
 = \frac{\lambda}{\min\{c, n\} \mu }p(n-1) 
 = \frac{1}{\min\{c, n\}}(c\rho) p(n-1) \\
 & = \frac{1}{\min\{c, n\}\min\{c, n-1\}}(c\rho)^2 p(n-2) \\
 &= \frac{1}{\Pi_{k=1}^{n}\min\{c, k\}}(c\rho)^{n} p(0). 
 \end{align*}
Thus, if $n<c$:
\begin{equation}
 p(n)
 % = \frac{1}{\Pi_{k=1}^{n}\min\{c, k\}}(c\rho)^{n} p(0)
 = \frac{(c\rho)^n}{n!} p(0),
\end{equation}
% since $\min\{c,k\}=k$ when $k<c$.
If $n\geq c$:
\begin{align*}
 p(n) 
%&= \frac{1}{\Pi_{k=1}^{n}\min\{c, k\}}(c\rho)^{n} p(0) \\
&= \frac{1}{\Pi_{k=1}^{c} k \cdot \Pi_{k=c+1}^{n} c}(c\rho)^{n} p(0) \\
&= \frac{1}{c! c^{n-c}}c^n\rho^{n} p(0) \\
&= \frac{c^c}{c!}\rho^{n} p(0).
\end{align*}


To obtain the normalization constant $G$,
\begin{align*}
1 &= \sum_{n=0}^\infty p(n) 
= \sum_{n=0}^{c-1} p(n) + \sum_{n=c}^\infty p(n) \\
&=p(0) \sum_{n=0}^{c-1}\frac{(c\rho)^n}{n!} + 
 p(0)\sum_{n=c}^{\infty} \frac{c^c}{c!} \rho^{n} \\
&=p(0)\sum_{n=0}^{c-1}\frac{(c\rho)^n}{n!} + 
 p(0) \sum_{n=c}^{\infty} \frac{(c\rho)^c}{c!} \rho^{n-c} \\
&= 
p(0)\sum_{n=0}^{c-1}\frac{(c\rho)^n}{n!} + 
p(0)\frac{(c\rho)^c}{c!} \sum_{n=0}^{\infty} \rho^n \\
&= 
p(0) \sum_{n=0}^{c-1}\frac{(c\rho)^n}{n!} + 
p(0)\frac{(c\rho)^c}{c!(1-\rho)}.
\end{align*}
Hence, 
\begin{equation}\label{eq:501}
 G= \sum_{n=0}^{c-1}\frac{(c\rho)^n}{n!} + \frac{(c\rho)^c}{c!(1-\rho)}.
\end{equation}

Next, 
\begin{align*}
 \E{L_Q} 
&=\sum_{n=c}^\infty (n-c) p(n) \\
&=\sum_{n=c}^\infty (n-c) \frac{c^c}{c!}\rho^{n} p(0) \\
&=\frac{c^c\rho^c}{G c!} \sum_{n=c}^\infty (n-c) \rho^{n-c} \\
&=\frac{c^c\rho^c}{G c!} \sum_{n=0}^\infty n \rho^n 
=\frac{c^c\rho^c}{G c!} \frac{\rho}{(1-\rho)^2}.
\end{align*}
% where, with our common trick (if we don't want to use generating functions),
% \begin{align*}
% \sum_{n=0}^\infty n \rho^n 
% &= \sum_{n=0}^\infty \sum_{i=1}^\infty \1{i\leq n} \rho^n
% = \sum_{i=1}^\infty \sum_{n=0}^\infty \1{i\leq n} \rho^n\\
% &= \sum_{i=1}^\infty \sum_{n=i}^\infty \rho^n
% = \sum_{i=1}^\infty \rho^i \sum_{n=0}^\infty \rho^n\\
% &= \frac1{1-\rho} \sum_{i=1}^\infty \rho^i 
% = \frac\rho{1-\rho} \sum_{i=0}^\infty \rho^i 
% = \frac\rho{(1-\rho)^2}.
% \end{align*}
% Observe again that using indicators and Fubini's theorem
% (interchanging summations and integrals) makes the above computation
% painless. Realize, by the way, that
% \begin{equation*}
% \sum_{n=0}^\infty n p(n) = \sum_{n=1}^\infty n p(n).
% \end{equation*}

% We next show that 
% by
% \begin{equation*}
% \E{L_S} = \sum_{n=0}^{c} n p(n) + \sum_{n=c+1}^{\infty} c p(n).
% \end{equation*}

The derivation of the expected number of jobs in service becomes easier if we pre-multiply the normalization constant $G$:
 \begin{align*}
 G \E{L_S}
&= G \left( \sum_{n=0}^{c} n p(n) + \sum_{n=c+1}^{\infty} c p(n) \right) \\
&= \sum_{n=1}^{c} n \frac{(c\rho)^n}{n!} + \sum_{n=c+1}^{\infty} c \frac{c^c\rho^n}{c!} 
= \sum_{n=1}^{c} \frac{(c\rho)^n}{(n-1)!} + \frac{c^{c+1}}{c!}\sum_{n=c+1}^{\infty} \rho^n\\
&= \sum_{n=0}^{c-1} \frac{(c\rho)^{n+1}}{n!} + \frac{(c\rho)^{c+1}}{c!}\sum_{n=0}^{\infty} \rho^n
= c\rho \left(\sum_{n=0}^{c-1} \frac{(c\rho)^n}{n!} + \frac{(c\rho)^{c}}{c!(1-\rho)}\right).
 \end{align*}
Observe that the right-hand side is precisely equal to $\rho c G$, and hence,
\begin{equation*}
 \E{L_S} = c\rho = \frac\lambda\mu.
\end{equation*}
\end{solution}
\end{exercise}

% \begin{align}
% \rho &= \frac{\lambda}{c\mu}, \label{eq:9} \\
% p(n) &= \frac{1}G \frac{(c\rho)^n}{n!}, \quad n=0,\ldots, c-1, \label{eq:502}\\
% p(n) &= \frac{1}G \frac{c^c\rho^n}{c!}, \quad n=c,c+1, \ldots\label{eq:58} \\
% G &=\sum_{n=0}^{c-1} \frac{(c\rho)^n}{n!} + \frac{(c\rho)^c}{(1-\rho)c!}, \label{eq:501}\\
% \E{L_Q} &= \sum_{n=c}^\infty (n-c) p(n) = \frac{(c\rho)^c}{c! G}\frac{\rho}{(1-\rho)^2}, \\ 
% \E{L_S} &= \sum_{n=0}^{c}n p(n) + \sum_{n=c+1}^\infty c p(n) = \frac{\lambda}\mu.
% \end{align}

\begin{extra}
 Check that the performance measures of the $M/M/c$ queue reduce to those of the $M/M/1$ queue if $c=1$.
\begin{hint}
Fill in $c=1$. Realize that this is a check on the formulas.
\end{hint}
\begin{solution}
Take $c=1$
\begin{subequations}
 \begin{align}
p(n) &= \frac{1}G \frac{(c\rho)^0}{0!}=\frac1 G, \quad n=0,\ldots, 1-1 \\
p(n) &= \frac{1}G \frac{c^c\rho^n}{c!} = \frac{1}G \frac{1^1\rho^n}{1!} =\frac{\rho^n}G , \quad n=1,1+1, \ldots \\
G &=\sum_{n=0}^{c-1} \frac{(c\rho)^n}{n!} + \frac{(c\rho)^c}{(1-\rho)c!}
=\sum_{n=0}^{0} \frac{\rho^0}{0!} + \frac{\rho}{(1-\rho)} = 1 + \frac{\rho}{1-\rho} = \frac1{1-\rho},
\\
\E{L_Q} &= \frac{(c\rho)^c}{c! G}\frac{\rho}{(1-\rho)^2} = \frac{\rho}{1/(1-\rho)}\frac{\rho}{(1-\rho)^2} = \frac{\rho^2}{1-\rho}, \\
\E{L_S} &= \sum_{n=0}^{c}n p(n) + \sum_{n=c+1}^\infty c p(n) = p(1) + 1 \sum_{n=2}^\infty p(n) = 1- p(0) = \rho.
\end{align}
\end{subequations}
Everything is in accordance to the formulas we derived earlier for the $M/M/1$ queue. 
\end{solution}
\end{extra}


\begin{exercise}\clabel{ex:27}
 It should be clear that the $M/M/c$ queue is a bit harder to analyze than the $M/M/1$ queue, at least the expressions are more extensive.
 It is tempting to approximate the $M/M/c$ queue by an $M/M/1$ queue with a server that works $c$ times as fast.
 As we now have the formulas for the $M/M/c$ queue and the $M/M/q$ queue we can use these to obtain some basic understanding of the difference.
 
 Let us therefore consider a numerical example.
 Suppose that we have an $M/M/3$ queue, with arrival rate $\lambda = 5$ per day and $\mu=2$ per server, and we compare it to an $M/M/1$ with the same arrival rate but with a service rate of $\mu = 3\cdot 2 = 6$.
 Make a graph of the ratios of $\E{L}$ and $\E{L_Q}$ of both models as a function of $\rho$.
 Explain why these ratios become $1$ as $\rho\uparrow 1$. 
\begin{solution}
I implement the formulas of~\cref{ex:7} in Python. First the results for the $M/M/3$ queue.

\begin{pyconsole}
from math import exp, factorial

labda = 5
mu = 2
c = 3

rho = labda / mu / c
rho

G = sum((c * rho)**n / factorial(n) for n in range(c))
G += (c * rho)**c / ((1 - rho) * factorial(c))
G

ELQ = (c * rho)**c / (factorial(c) * G) * rho / (1 - rho)**2
ELQ
ELS = rho * c
ELS
EL = ELQ + ELS
EL
\end{pyconsole}

Now for the $M/M/1$ queue:

\begin{pyconsole}
labda = 5
c = 3
mu = 2*c

rho = labda / mu 
rho

ELQ = rho**2/(1-rho)
ELQ
ELS = rho
ELS
EL = ELS + ELQ
EL

rho/(1-rho) # this must also be EL, just a check
\end{pyconsole}

Note the last check. As a rule, you should always compare your results
with known results. BTW, that is one of the reasons I prefer to code
the formulas instead of using a calculator. Testing with code is
relatively easy, whereas with a calculator it is impossible. (You
simply can't check what you typed at the calculator.)

So, returning to the results, as expected, the number of jobs in queue
is smaller for the $M/M/3$ queue, but the number in service is higher.

To put things in a larger perspective, see
the figure below where we plot the ratio of the queue
lengths and the system length as functions of $\rho$. We see, in case
of high load, that $\E{L_Q}$ and $\E L$ are nearly the same for both
systems. This is as expected: when the load is high, most jobs should
be in the queue. Therefore, $\E{L_Q}/\E L \to 1$ as $\rho\to 1$. When
$\rho$ is small, the difference is quite large. This is also
reasonable, because the service time in the fast $M/M/1$ is 3 times as
small as the service time in the $M/M/3$ queue. Hence, as $\rho$ is
small, the time in the system is dominated by service time, as there
is hardly any queueing time, if at all. Thus, there must be more jobs
in the system on average in the $M/M/3$ queue than in the fast $M/M/1$
queue.

\begin{center}
% see progs/multi_server_queue.py
\input{progs/multi_vs_single_server.tex}
\end{center}

The code can be found on \texttt{github} in the \texttt{progs} directory.
\end{solution}
\end{exercise}


\begin{exercise}\clabel{ex:l-245}
 Model the $M/M/c/c$ queue in terms of an $M(n)/M(n)/1$ queue and determine the performance measures.
 This model is also known as the Erlang $B$-formula and is often used to determine the number of beds at hospitals, where the beds act as servers and the patients as jobs.
\begin{solution} Take,
 $\lambda(n) = \lambda$ if $n< c$, and $\lambda(n)=0$ for $n\geq c$. Also, let, $\mu(n) = n \mu$ for $n\leq c$. (And $n$ can never be larger than $c$, since $\lambda(n) = 0$ for $n\geq c$.) Define $\rho = \lambda/(c \mu)$. Then, we see that $p(n) = p(0)(c\rho)^n/n!$. For the normalization
 \begin{equation*}
 1=\sum_{n=0}^c p(n) = p(0) \sum_{n=0}^c \frac{(c\rho)^n}{n!}.
 \end{equation*}
Thus, the normalization constant $G=\sum_{n=0}^{c} \frac{(c\rho)^n}{n!}$, and $p(0)=G^{-1}$. 

Since there are as many servers as places available in the system, $\E{L_Q}=0$. The expected number of servers busy is
 \begin{align*}
 \E{L_S} 
&= \sum_{n=0}^{c} n p(n) = \sum_{n=1}^c n p(n) \\
&= G^{-1} \sum_{n=1}^c n \frac{(\lambda/\mu)^n}{n!} 
= G^{-1} \sum_{n=1}^{c} \frac{(\lambda/\mu)^{n}}{(n-1)!} \\
&= \frac{\lambda}{\mu G} \sum_{n=0}^{c-1} \frac{(\lambda/\mu)^{n}}{n!} 
= \frac{\lambda}{G\mu} \left(G- \frac{(\lambda/\mu)^c}{c!}\right) \\
&= \frac{\lambda}{\mu} \left(1- \frac{1}G\frac{(\lambda/\mu)^c}{c!}\right) \\
&= \frac{\lambda}{\mu} \left(1- p(c)\right).
 \end{align*}
This can be explained as follows: $\lambda(1-p(c))$ is the rate of accepted jobs (since a fraction $p(c)$ is lost). Thus, the load is $\lambda(1-p(c))/\mu$, and the load is the fraction of time the servers are busy. 
\end{solution}
\end{exercise}

\begin{exercise}\clabel{ex:l-246}
 Take the limit $c\to \infty$ in the $M/M/c$ queue (or the $M/M/c/c$ queue) and obtain the performance measures for the $M/M/\infty$ queue, i.e., a queueing system with ample servers.
\begin{hint}
Use that for any $x$, $x^n/n!\to 0$ as $n\to\infty$.
\end{hint}
\begin{solution}
 By taking the limit $c\to\infty$, note first that in~\cref{eq:501},
\begin{equation*}
\frac{(c\rho)^c}{(1-\rho)c!} = \frac{(\lambda/\mu)^c}{(1-\rho)c!}\to 0, \quad\text{as } c\to \infty.
\end{equation*}
Hence
\begin{equation*}
G =\sum_{n=0}^{c-1} \frac{(c\rho)^n}{n!} + \frac{(c\rho)^c}{(1-\rho)c!} \to \sum_{n=0}^{\infty} \frac{(c\rho)^n}{n!} = e^{\lambda/\mu}.
\end{equation*}
Next, for any fixed $n$, eventually $c>n$, and then, as $\rho=\lambda/(\mu c)$, 
\begin{equation*}
 p(n) = \frac{1}G \frac{(c\rho)^n}{n!} = \frac{1}G \frac{(\lambda/\mu)^n}{n!} 
\to e^{-\lambda/\mu} \frac{(\lambda/\mu)^n}{n!}, \quad\text{as } c\to\infty.
\end{equation*}
Moreover, there is no fixed $n$ such that $n>c$. Thus, the probabilities in~\cref{ex:7} are no longer present. Thus, we see that the number of busy servers in the $M/M/\infty$ queue is
Poisson distributed with parameter $\lambda/\mu$, and
$\E{L} = \E{L_S} = \lambda/\mu$. Observe that now $\lambda/\mu$ has
no longer the interpretation of the fraction of time the server(s) are
busy; it is the average number of busy servers.

We mention in passing---but do not
prove it---that the same results also hold for the $M/G/\infty$ queue
with $\lambda \E S$ rather than $\lambda/\mu$.
\end{solution}


\end{exercise}

\begin{extra}
 Show that the $M/M/\infty$ queue is stable for any finite $\lambda$. 
\begin{solution}
 No matter how many jobs are in service, there is always another
 free server available when a new job arrives. Thus, jobs never have
 to wait in queue, and only spend time in service. Since
 $\E S < \infty$ by assumption, jobs spend a finite time (with
 probability one) at a server.
\end{solution}
\end{extra}

\begin{extra}
 Why is $\E L=\rho$ for the $M/M/\infty$ queue? 
\begin{solution}
 Write $\rho = \lambda /\mu$.
 Then, from the formulas for the $M/M/\infty$ queue, it follows that $p(n) = e^{-\rho} \rho^n/n!$.
 Interestingly, we see that this is equal to $\P{N=n}$ where $N$ is a Poisson r.v.
 with parameter $\rho$.
 Thus, the number in the system $L$ is Poisson distributed with parameter $\rho$, thus $\E L = \rho$.

 Another way to see that $\E L=\rho$ is by noting that in the $M/M/\infty$ queue jobs do not interact with each other in the queue.
 When they arrive, there is always a free server available.
 Since work arrives at rate $\rho$, and all jobs are in service simultaneously, the average number of busy servers must also be $\rho$.
\end{solution}
\end{extra}



\begin{extra}
Consider the $M/M/2/3$ queue with arrival rate $\lambda$ and
service rate $\mu$ (thus, at most 2 jobs can be in service and 1 in queue).
 Derive first the level-crossing equations for this queueing system, then derive closed form expressions for the state probabilities in steady state. 
\begin{hint}
 Think about what would be the appropriate model choices for
 $\lambda(n)$ and $\mu(n)$ and use the level-crossing equations
 $\lambda(n) p(n) = \mu(n+1)p(n+1)$. For instance, realize that
 $\lambda(3)=0$: the system cannot contain more than 3 jobs, hence a
 state with $4$ jobs must be impossible. We can achieve that by
 setting $\lambda(3)=0$. For the service rate, how many servers are
 busy when the system contains 2 or more jobs? What does this say
 about $\mu(k)$ for $k=2$ or $k=3$.
\end{hint}
\begin{solution}
 Use the figure below. Make sure you understand why $\mu(2)=2\mu$ and so on. 
 \begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.8cm,
 semithick]
 \node[state] (0) {$p(0)$} ;
 \node[state] (1) [right of=0] {$p(1)$};
 \node[state] (2) [right of=1] {$p(2)$};
 \node[state] (3) [right of=2] {$p(3)$};

\path 
 (0) edge [bend left] node {$\lambda$} (1)
 (1) edge [bend left] node {$\mu$} (0)
 (1) edge [bend left] node {$\lambda$} (2)
 (2) edge [bend left] node {$2\mu$} (1)
 (2) edge [bend left] node {$\lambda$} (3)
 (3) edge [bend left] node {$2\mu$} (2);
\end{tikzpicture}
 
 \end{center}

From this figure it follows right away that:
 \begin{align*}
 \lambda p(0) &= \mu p(1), \\
 \lambda p(1) &= 2\mu p(2), \\
 \lambda p(2) &= 2\mu p(3).\\
 \end{align*}

Then, from the above, with $\rho=\lambda/\mu$: 
 \begin{align*}
 p(1) &= \rho p(0), \\
 p(2) &= (\rho/2) p(1) = (\rho^2/2) p(0), \\
 p(3) &= (\rho/2) p(2) = (\rho^3/4) p(0).
 \end{align*}
Now we normalize to find $p(0)$. Thus, we want that:
\begin{equation*}
 1 = p(0)+p(1)+p(2)+p(3) = p(0)\left(1 + \rho + \frac{\rho^2}2 + \frac{\rho^3}4\right),
\end{equation*}
hence,
\begin{equation*}
p(0) = (1+\rho + \rho^2/2 + \rho^3/4)^{-1}.
\end{equation*}
\end{solution}
\end{extra}


\begin{extra}[Multi-server queue with blocking]\clabel{ex:41}
 Consider the $M/M/c/c+K$ queue in which at most $c$ jobs can be in service and $K$ in queue.
 Try to derive the steady state probabilities $p(0)$, $p(1), \ldots$.
 You do not have to compute the normalization constant $G$.
\begin{hint}
Use $\lambda(n) p(n) = \mu(n+1)p(n+1)$ and
 find suitable expressions for $\lambda(n)$ and $\mu(n+1)$. 
\end{hint}
\begin{solution}
 $\lambda(n) \equiv \lambda$ for all $n<c+K$. When $n=c+K$,
 $\lambda(n)=0$, since then the system is full, and all arriving
 jobs will be dropped; in other words, there will still be jobs
 arriving to the system when $L=c+K$, but these jobs will be
 rejected, hence cannot generate a transition from state $c+K$ to
 $c+K+1$. When $n<c$, $\mu(n)=n \mu$ since only $n$ servers
 are active/occupied when the system contains $n$ jobs. When
 $n\geq c$, $\mu(n) = c \mu$. Thus, using $\rho=\lambda/(c\mu)$, for $n<c$,
 \begin{equation*}
 p(n) = \frac{\lambda}{n\mu} p(n-1) = \frac{(\lambda/\mu)^n}{n!} p(0)=\frac{(c\rho)^n}{n!}p(0).
 \end{equation*}
For $c\leq n\leq c+K$ and using the above to get $p(c-1)$:
 \begin{align*}
 p(n) &= \frac{\lambda}{c\mu} p(n-1) 
= \rho p(n-1) = \rho^2 p(n-2) = \ldots\\
&=\rho^{n-c+1} p(c-1) 
=\rho^{n-c+1} \frac{(c\rho)^{c-1}}{(c-1)!}p(0)\\
&=\rho^{n} \frac{(c)^{c-1}}{(c-1)!}p(0) 
=\rho^{n} \frac{(c)^{c-1}c}{(c-1)!c}p(0) =\frac{c^c \rho^n}{c!} p(0).
 \end{align*}
The normalization is trivial, numerically at least.
\end{solution}
\end{extra}




\begin{exercise}\clabel{ex:l-247}
 Derive the steady state probabilities $p(n)$ for a single-server queue with a finite calling population with $N$ jobs, i.e., jobs that are in service cannot arrive to the system.
 Check the answer you obtained for the cases $N=1$ and $N=2$. What happens if $N\to\infty$? 
 Interpret the results.
\begin{hint}
Use $\lambda(n) p(n) = \mu(n+1)p(n+1)$, and realize that for
 this case $\lambda(n) = (N-n)\lambda$ and $\mu(n) = \mu$.
\end{hint}
\begin{solution}
 Take $\lambda(n) = (N-n)\lambda$ and $\mu(n) = \mu$, and solve~\cref{eq:25,eq:20}.
 Thus:
 \begin{align*}
 p(n+1) 
& = \frac{(N-n)\lambda}\mu p(n) 
 = \rho (N-n) p(n) \\
& = \rho^2 (N-n)(N-(n-1))p(n-1) \\
& = \rho^3 (N-n)(N-(n-1))(N-(n-2)) p(n-2) \\
& = \rho^{n+1} (N-n)(N-(n-1))\cdots(N-(0)) p(0) \\
&= \rho^{n+1} \frac{N!}{(N-(n+1))!}p(0). 
 \end{align*}
 Next, we need to normalize this. Observe that
 $p(N+1)=p(N+2) = \ldots = 0$ since there are just $N$ customers,
 so that the system can never contain more than $N$
 customers. Thus, we want $p(0)$ to be such that
\begin{equation*}
 1 = \sum_{n=0}^N p(n) = p(0) \sum_{n=0}^N \rho^n \frac{N!}{(N-n)!}.
\end{equation*}
We see from this that $p(0)$ times some constant must be $1$. Hence, dividing by this constant, we get 
\begin{equation*}
 p(0) = \left(\sum_{n=0}^N \rho^n \frac{N!}{(N-n)!}\right)^{-1}.
\end{equation*}
I asked WolframAlpha to simplify this, but the answer I got was not particularly revealing. 
\end{solution}
\end{exercise}

\begin{exercise}\clabel{ex:l-248}
 Give an example of a system with a finite calling population.
\begin{solution}
 A finite calling population occurs for instance at a factory with a number of machines.
 When a machine breaks down, it becomes a (repair) job at the repair department.
 Thus, a break down forms an arrival at the repair shop.
 The mechanics at the repair department form a set of parallel servers.
 Typically, the number of machines is quite small, 10 or so, and when a machine is `down', i.e., broken, it cannot break again.
 Hence, when 2, say, machines are in repair, the number of `customers' that can arrive to the queueing system is only 8.
\end{solution}
\end{exercise}


\begin{extra} Derive the steady state probabilities $p(n)$ for a queue with a finite calling population with $N$ jobs and $N$ servers, i.e., the number of servers in the queueing system is equal to the size of the calling population. What happens if $N\to\infty$? 
\begin{solution}
 Take $\lambda(n) = (N-n)\lambda$ and $\mu(n) = n \mu$. Then 
 \begin{align*}
 p(n+1) 
&= \frac{\lambda(n)}{\mu(n+1)} p(n) 
= \frac{(N-n)\lambda}{(n+1)\mu} p(n) 
= \frac{(N-n)(N-(n-1))}{(n+1)n}\frac{\lambda^2}{\mu^2} p(n-1) \\
&= \frac{N!}{(N-(n+1))!}\frac1{(n+1)!}\rho^{n+1} p(0) 
 = {N \choose n+1}\rho^{n+1} p(0).
 \end{align*}
 Hence, after normalization, i.e., requiring that $p(0)$ is such
 that $\sum_{n=0}^N p(n) = 1$, so that $p(0) = \left(\sum_{k=0}^N \rho^k { N \choose k} \right)^{-1}$, the final result becomes
\begin{equation*}
 p(n) = \frac{\rho^n {N \choose n}}{\sum_{k=0}^N \rho^k {N \choose k}}.
\end{equation*}
\end{solution}
\end{extra}



Finally, we consider queues with \recall{balking}, that is, queues in
which customers leave when they find the queue too long at the moment
they arrive. A simple example model with customer balking is given by 
 \begin{equation*}
 \lambda(n) = 
 \begin{cases}
 \lambda, &\text{ if } n=0, \\
 \lambda/2, &\text{ if } n=1, \\
 \lambda/4, &\text{ if } n=2, \\
 0, &\text{ if } n > 2, \\
 \end{cases}
 \end{equation*}
and $\mu(n)=\mu$. 

Observe that here we make a subtle implicit assumption; in~\cref{sec:poisson-arrivals-see} we elaborate on this assumption.
To make the problem clear, note that balking customers \emph{decide at the moment they arrive} to either join or leave; in other words, they decide based on what they `see upon arrival'.
In yet other words, they make decisions based on the state of the system at arrival moments, not on time-averages.
However, the notion of $p(n)$ is a long-run \emph{time-average}, and is typically not the same as what customers `see upon arrival'.
As a consequence, the performance measure $\P{L\leq n}$ is not necessarily in accordance with the perception of customers.
To relate these two `views', i.e., time-average versus observer-average, we need a new concept, \emph{PASTA}, to be developed in~\cref{sec:poisson-arrivals-see}.


\begin{exercise}\clabel{ex:l-249}
 In what way is a queueing system with balking, at level $b$ say, different from a queueing system with finite calling population of size $b$?
\begin{solution}
 In a queueing system with balking, customers may decide to balk at a level $b$.
 Thus, whether only $b$ customers are admitted to the system (i.e., blocked), or balk at level $b$, the effect is the same: the number of people in the system remains at or below $b$.
 However, a fraction of the customers may already balk at lower levels, like in the example above, so that the arrival stream is `thinned' due to balking customers.
 In that respect, a queueing system with balking behaves differently.
\end{solution}
\end{exercise}





\opt{solutionfiles}{
\Closesolutionfile{hint}
\Closesolutionfile{ans}
\subsection*{Hints}
\input{hint}
\subsection*{Solutions}
\input{ans}
}

%\clearpage

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../companion"
%%% End:
